/data/dylu/anaconda3/envs/bdetr2d/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/data/dylu/anaconda3/envs/bdetr2d/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Not using distributed mode
Namespace(GT_type='separate', aux_loss=True, backbone='resnet101', batch_size=2, bbox_loss_coef=5, butd=False, cache_mode=False, ce_loss_coef=1, clip_max_norm=0.1, cls_loss_coef=2, coco_boxes_path='/data/beauty_detr/extra_data/coco_boxes.lmdb', coco_panoptic_path=None, coco_path='', coco_path_refcoco='/data/beauty_detr', combine_datasets=['talk2event'], combine_datasets_val=['talk2event'], contrastive_align_loss=True, contrastive_align_loss_coef=1, contrastive_loss_coef=0.1, contrastive_loss_hdim=64, custom_coco_ann_path='', custom_coco_id2name_path='', custom_coco_img_path_train='', custom_coco_img_path_val='', custom_text='all objects', dataset_config='configs/pretrain.json', dataset_file='refexp', debug=False, dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=2048, distributed=False, dropout=0.1, ema=True, ema_decay=0.9998, embeddings_path='/data/beauty_detr/extra_data/class_embeddings.npy', enc_layers=6, enc_n_points=4, eos_coef=0.1, epoch_chunks=-1, epochs=20, eval=False, eval_skip=1, flickr_ann_path='OpenSource', flickr_boxes_path='/data/beauty_detr/extra_data/flickr_boxes_correct.lmdb', flickr_dataset_path='../temp/flickr30k_entities/', flickr_img_path='data/flickr30k-images', focal_alpha=0.25, fraction_warmup_steps=0.01, freeze_text_encoder=False, giou_loss_coef=2, gqa_ann_path='OpenSource', hidden_dim=256, img_path='img.jpg', large_scale=True, lr=1e-05, lr_backbone=1e-06, lr_backbone_names=['backbone.0'], lr_drop=9, lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], mask_loss_coef=1, new_contrastive=True, nheads=8, num_feature_levels=4, num_queries=300, num_workers=2, output_dir='exps/pretrain_talk2event', position_embedding='sine', position_embedding_scale=6.283185307179586, refexp_ann_path='OpenSource', refexp_dataset_name='refcoco', remove_difficult=False, resume='/data/dylu/project/butd_detr/data/pretrain_2d.pth', run_dir='exp1', run_name='', save_freq=1, schedule='linear_with_warmup', seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, set_loss='hungarian', sgd=False, start_epoch=0, temperature_NCE=0.07, test=False, test_type='test', text_encoder_lr=6e-06, text_encoder_type='roberta-base', two_stage=True, val_batch_size=2, vg_ann_path='', vg_boxes_path='/data/beauty_detr/extra_data/gqa_boxes.lmdb', vg_img_path='/data/beauty_detr/images/', visualize=False, visualize_custom_image=False, wandb=False, weight_decay=0.0001, with_box_refine=True, with_learned_class_embeddings=True)
Initializing Talk2EventDataset
load 7369 data from test split
missing 296 attributes
Initializing Talk2EventDataset
load 7369 data from test split
missing 296 attributes
Unexpected Keys: ['transformer.box_mlp.0.weight', 'transformer.box_mlp.0.bias', 'transformer.box_mlp.1.weight', 'transformer.box_mlp.1.bias', 'transformer.butd_box_embedding.0.weight', 'transformer.butd_box_embedding.0.bias', 'transformer.butd_box_embedding.1.weight', 'transformer.butd_box_embedding.1.bias', 'transformer.butd_class_embeddings.weight', 'transformer.encoder.layers.0.cross_d.in_proj_weight', 'transformer.encoder.layers.0.cross_d.in_proj_bias', 'transformer.encoder.layers.0.cross_d.out_proj.weight', 'transformer.encoder.layers.0.cross_d.out_proj.bias', 'transformer.encoder.layers.0.norm_d.weight', 'transformer.encoder.layers.0.norm_d.bias', 'transformer.encoder.layers.1.cross_d.in_proj_weight', 'transformer.encoder.layers.1.cross_d.in_proj_bias', 'transformer.encoder.layers.1.cross_d.out_proj.weight', 'transformer.encoder.layers.1.cross_d.out_proj.bias', 'transformer.encoder.layers.1.norm_d.weight', 'transformer.encoder.layers.1.norm_d.bias', 'transformer.encoder.layers.2.cross_d.in_proj_weight', 'transformer.encoder.layers.2.cross_d.in_proj_bias', 'transformer.encoder.layers.2.cross_d.out_proj.weight', 'transformer.encoder.layers.2.cross_d.out_proj.bias', 'transformer.encoder.layers.2.norm_d.weight', 'transformer.encoder.layers.2.norm_d.bias', 'transformer.encoder.layers.3.cross_d.in_proj_weight', 'transformer.encoder.layers.3.cross_d.in_proj_bias', 'transformer.encoder.layers.3.cross_d.out_proj.weight', 'transformer.encoder.layers.3.cross_d.out_proj.bias', 'transformer.encoder.layers.3.norm_d.weight', 'transformer.encoder.layers.3.norm_d.bias', 'transformer.encoder.layers.4.cross_d.in_proj_weight', 'transformer.encoder.layers.4.cross_d.in_proj_bias', 'transformer.encoder.layers.4.cross_d.out_proj.weight', 'transformer.encoder.layers.4.cross_d.out_proj.bias', 'transformer.encoder.layers.4.norm_d.weight', 'transformer.encoder.layers.4.norm_d.bias', 'transformer.encoder.layers.5.cross_d.in_proj_weight', 'transformer.encoder.layers.5.cross_d.in_proj_bias', 'transformer.encoder.layers.5.cross_d.out_proj.weight', 'transformer.encoder.layers.5.cross_d.out_proj.bias', 'transformer.encoder.layers.5.norm_d.weight', 'transformer.encoder.layers.5.norm_d.bias', 'transformer.decoder.layers.0.cross_d.in_proj_weight', 'transformer.decoder.layers.0.cross_d.in_proj_bias', 'transformer.decoder.layers.0.cross_d.out_proj.weight', 'transformer.decoder.layers.0.cross_d.out_proj.bias', 'transformer.decoder.layers.0.norm_d.weight', 'transformer.decoder.layers.0.norm_d.bias', 'transformer.decoder.layers.1.cross_d.in_proj_weight', 'transformer.decoder.layers.1.cross_d.in_proj_bias', 'transformer.decoder.layers.1.cross_d.out_proj.weight', 'transformer.decoder.layers.1.cross_d.out_proj.bias', 'transformer.decoder.layers.1.norm_d.weight', 'transformer.decoder.layers.1.norm_d.bias', 'transformer.decoder.layers.2.cross_d.in_proj_weight', 'transformer.decoder.layers.2.cross_d.in_proj_bias', 'transformer.decoder.layers.2.cross_d.out_proj.weight', 'transformer.decoder.layers.2.cross_d.out_proj.bias', 'transformer.decoder.layers.2.norm_d.weight', 'transformer.decoder.layers.2.norm_d.bias', 'transformer.decoder.layers.3.cross_d.in_proj_weight', 'transformer.decoder.layers.3.cross_d.in_proj_bias', 'transformer.decoder.layers.3.cross_d.out_proj.weight', 'transformer.decoder.layers.3.cross_d.out_proj.bias', 'transformer.decoder.layers.3.norm_d.weight', 'transformer.decoder.layers.3.norm_d.bias', 'transformer.decoder.layers.4.cross_d.in_proj_weight', 'transformer.decoder.layers.4.cross_d.in_proj_bias', 'transformer.decoder.layers.4.cross_d.out_proj.weight', 'transformer.decoder.layers.4.cross_d.out_proj.bias', 'transformer.decoder.layers.4.norm_d.weight', 'transformer.decoder.layers.4.norm_d.bias', 'transformer.decoder.layers.5.cross_d.in_proj_weight', 'transformer.decoder.layers.5.cross_d.in_proj_bias', 'transformer.decoder.layers.5.cross_d.out_proj.weight', 'transformer.decoder.layers.5.cross_d.out_proj.bias', 'transformer.decoder.layers.5.norm_d.weight', 'transformer.decoder.layers.5.norm_d.bias', 'backbone.0.butd_class_embeddings.weight', 'backbone.backbone.butd_class_embeddings.weight']
Start training
Epoch: [13]  [   0/3684]  eta: 1:18:18  loss: 289.4017 (289.4017)  time: 1.2753  data: 0.0001  max mem: 9385
Epoch: [13]  [ 100/3684]  eta: 0:53:34  loss: 101.5628 (153.9832)  time: 0.9167  data: 0.0000  max mem: 17237
Epoch: [13]  [ 200/3684]  eta: 0:51:51  loss: 83.2097 (124.8666)  time: 0.8731  data: 0.0000  max mem: 17237
Epoch: [13]  [ 300/3684]  eta: 0:50:30  loss: 68.9616 (112.3683)  time: 0.9082  data: 0.0000  max mem: 17237
Epoch: [13]  [ 400/3684]  eta: 0:48:49  loss: 90.0241 (107.9258)  time: 0.8845  data: 0.0000  max mem: 17760
Epoch: [13]  [ 500/3684]  eta: 0:47:11  loss: 60.8100 (102.8303)  time: 0.8653  data: 0.0000  max mem: 17913
Epoch: [13]  [ 600/3684]  eta: 0:45:33  loss: 78.4931 (99.0925)  time: 0.8408  data: 0.0000  max mem: 17913
Epoch: [13]  [ 700/3684]  eta: 0:43:58  loss: 76.0759 (97.4963)  time: 0.8627  data: 0.0000  max mem: 18051
Epoch: [13]  [ 800/3684]  eta: 0:42:34  loss: 48.5003 (94.4137)  time: 0.8922  data: 0.0000  max mem: 18051
Epoch: [13]  [ 900/3684]  eta: 0:41:04  loss: 91.8724 (92.3577)  time: 0.8844  data: 0.0000  max mem: 18051
Epoch: [13]  [1000/3684]  eta: 0:39:31  loss: 67.4840 (90.5721)  time: 0.8424  data: 0.0000  max mem: 18051
Epoch: [13]  [1100/3684]  eta: 0:38:00  loss: 74.3012 (89.1838)  time: 0.8728  data: 0.0000  max mem: 18051
Epoch: [13]  [1200/3684]  eta: 0:36:31  loss: 74.7642 (87.4965)  time: 0.8879  data: 0.0000  max mem: 18051
Epoch: [13]  [1300/3684]  eta: 0:35:00  loss: 77.9357 (87.0875)  time: 0.8587  data: 0.0000  max mem: 18051
Epoch: [13]  [1400/3684]  eta: 0:33:30  loss: 72.1410 (86.6232)  time: 0.8847  data: 0.0000  max mem: 18051
Epoch: [13]  [1500/3684]  eta: 0:31:59  loss: 56.6710 (85.6646)  time: 0.8513  data: 0.0000  max mem: 18051
Epoch: [13]  [1600/3684]  eta: 0:30:30  loss: 26.1839 (84.0049)  time: 0.8523  data: 0.0000  max mem: 18051
Epoch: [13]  [1700/3684]  eta: 0:29:02  loss: 33.1883 (83.4700)  time: 0.8556  data: 0.0000  max mem: 18051
Epoch: [13]  [1800/3684]  eta: 0:27:33  loss: 50.2256 (82.3261)  time: 0.8984  data: 0.0000  max mem: 18051
Epoch: [13]  [1900/3684]  eta: 0:26:07  loss: 60.7687 (81.6840)  time: 0.8791  data: 0.0000  max mem: 18051
Epoch: [13]  [2000/3684]  eta: 0:24:37  loss: 64.8107 (81.0306)  time: 0.8996  data: 0.0000  max mem: 18131
Epoch: [13]  [2100/3684]  eta: 0:23:10  loss: 51.4144 (80.4399)  time: 0.8930  data: 0.0000  max mem: 18131
Epoch: [13]  [2200/3684]  eta: 0:21:42  loss: 48.0697 (79.7514)  time: 0.8604  data: 0.0000  max mem: 18131
Epoch: [13]  [2300/3684]  eta: 0:20:14  loss: 57.5479 (79.2064)  time: 0.8916  data: 0.0000  max mem: 18826
Epoch: [13]  [2400/3684]  eta: 0:18:46  loss: 62.1901 (78.7112)  time: 0.8567  data: 0.0000  max mem: 18826
Epoch: [13]  [2500/3684]  eta: 0:17:18  loss: 62.5625 (78.1970)  time: 0.8875  data: 0.0000  max mem: 19947
Epoch: [13]  [2600/3684]  eta: 0:15:50  loss: 33.9692 (77.6300)  time: 0.9161  data: 0.0000  max mem: 19947
Epoch: [13]  [2700/3684]  eta: 0:14:22  loss: 80.4710 (77.4528)  time: 0.8602  data: 0.0000  max mem: 19947
Epoch: [13]  [2800/3684]  eta: 0:12:54  loss: 45.6302 (77.0637)  time: 0.8779  data: 0.0000  max mem: 19947
Epoch: [13]  [2900/3684]  eta: 0:11:26  loss: 65.7229 (76.5166)  time: 0.8569  data: 0.0000  max mem: 19947
Epoch: [13]  [3000/3684]  eta: 0:09:59  loss: 30.9687 (76.0251)  time: 0.8634  data: 0.0000  max mem: 19947
Epoch: [13]  [3100/3684]  eta: 0:08:31  loss: 71.2136 (75.8402)  time: 0.8512  data: 0.0000  max mem: 19947
Epoch: [13]  [3200/3684]  eta: 0:07:03  loss: 53.1456 (75.7933)  time: 0.9079  data: 0.0000  max mem: 19947
Epoch: [13]  [3300/3684]  eta: 0:05:36  loss: 59.6996 (75.4094)  time: 0.8510  data: 0.0000  max mem: 19947
Epoch: [13]  [3400/3684]  eta: 0:04:08  loss: 49.1534 (75.1408)  time: 0.9128  data: 0.0000  max mem: 19947
Epoch: [13]  [3500/3684]  eta: 0:02:41  loss: 80.9844 (74.8690)  time: 0.8546  data: 0.0000  max mem: 19947
Epoch: [13]  [3600/3684]  eta: 0:01:13  loss: 42.9440 (74.5890)  time: 0.8482  data: 0.0000  max mem: 19947
Epoch: [13]  [3683/3684]  eta: 0:00:00  loss: 59.3179 (74.2684)  time: 0.8794  data: 0.0000  max mem: 19947
Epoch: [13] Total time: 0:53:41 (0.8744 s / it)
Averaged stats: loss: 59.3179 (74.2684)
Evaluating talk2event
/data/dylu/anaconda3/envs/bdetr2d/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Test:  [   0/3685]  eta: 0:22:53  loss: 108.6257 (108.6257)  time: 0.3726  data: 0.2539  max mem: 19947
Test:  [ 500/3685]  eta: 0:05:10  loss: 59.5656 (82.2737)  time: 0.0969  data: 0.0001  max mem: 19947
Test:  [1000/3685]  eta: 0:04:20  loss: 42.5923 (99.3496)  time: 0.0964  data: 0.0001  max mem: 19947
Test:  [1500/3685]  eta: 0:03:31  loss: 63.4913 (117.4259)  time: 0.0959  data: 0.0001  max mem: 19947
Test:  [2000/3685]  eta: 0:02:43  loss: 51.9028 (115.2237)  time: 0.0960  data: 0.0001  max mem: 19947
Test:  [2500/3685]  eta: 0:01:54  loss: 58.0011 (109.7115)  time: 0.0959  data: 0.0001  max mem: 19947
Test:  [3000/3685]  eta: 0:01:06  loss: 84.1211 (107.0139)  time: 0.0964  data: 0.0001  max mem: 19947
Test:  [3500/3685]  eta: 0:00:17  loss: 89.0671 (104.9541)  time: 0.0962  data: 0.0001  max mem: 19947
Test:  [3684/3685]  eta: 0:00:00  loss: 40.5374 (104.8026)  time: 0.0991  data: 0.0001  max mem: 19947
Test: Total time: 0:05:56 (0.0967 s / it)
Averaged stats: loss: 40.5374 (104.8026)
/data/dylu/anaconda3/envs/bdetr2d/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/data/dylu/anaconda3/envs/bdetr2d/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
Epoch: [14]  [   0/3684]  eta: 1:02:39  loss: 87.2726 (87.2726)  time: 1.0205  data: 0.0000  max mem: 19947
Epoch: [14]  [ 100/3684]  eta: 0:52:19  loss: 47.5734 (60.5232)  time: 0.8743  data: 0.0000  max mem: 19947
Epoch: [14]  [ 200/3684]  eta: 0:50:19  loss: 41.7228 (59.7706)  time: 0.8612  data: 0.0000  max mem: 19947
Epoch: [14]  [ 300/3684]  eta: 0:49:03  loss: 32.3959 (59.3410)  time: 0.8460  data: 0.0000  max mem: 19947
Epoch: [14]  [ 400/3684]  eta: 0:47:37  loss: 64.9564 (61.5479)  time: 0.8503  data: 0.0000  max mem: 19947
Epoch: [14]  [ 500/3684]  eta: 0:46:18  loss: 60.5969 (61.8893)  time: 0.9043  data: 0.0000  max mem: 19947
Epoch: [14]  [ 600/3684]  eta: 0:44:54  loss: 66.1392 (63.1890)  time: 0.8942  data: 0.0000  max mem: 19947
Epoch: [14]  [ 700/3684]  eta: 0:43:25  loss: 49.1779 (63.5885)  time: 0.8636  data: 0.0000  max mem: 19947
Epoch: [14]  [ 800/3684]  eta: 0:41:54  loss: 23.2186 (63.3481)  time: 0.8629  data: 0.0000  max mem: 19947
Epoch: [14]  [ 900/3684]  eta: 0:40:22  loss: 61.5860 (62.8557)  time: 0.8645  data: 0.0000  max mem: 19947
Epoch: [14]  [1000/3684]  eta: 0:38:56  loss: 61.2926 (62.4928)  time: 0.8865  data: 0.0000  max mem: 19947
Epoch: [14]  [1100/3684]  eta: 0:37:25  loss: 46.0044 (62.2460)  time: 0.8421  data: 0.0000  max mem: 19947
Epoch: [14]  [1200/3684]  eta: 0:35:55  loss: 48.9753 (62.0500)  time: 0.8372  data: 0.0000  max mem: 19947
Epoch: [14]  [1300/3684]  eta: 0:34:34  loss: 46.1320 (62.1309)  time: 0.8412  data: 0.0000  max mem: 20519
Epoch: [14]  [1400/3684]  eta: 0:33:08  loss: 63.0446 (62.2028)  time: 0.8645  data: 0.0000  max mem: 20519
Epoch: [14]  [1500/3684]  eta: 0:31:41  loss: 51.6236 (62.0791)  time: 0.8314  data: 0.0000  max mem: 20519
Epoch: [14]  [1600/3684]  eta: 0:30:11  loss: 36.0400 (61.7794)  time: 0.8393  data: 0.0000  max mem: 20519
Epoch: [14]  [1700/3684]  eta: 0:28:42  loss: 41.5597 (61.6291)  time: 0.8431  data: 0.0000  max mem: 20519
Epoch: [14]  [1800/3684]  eta: 0:27:15  loss: 32.1728 (61.5193)  time: 0.8813  data: 0.0000  max mem: 20519
Epoch: [14]  [1900/3684]  eta: 0:25:48  loss: 65.6346 (61.8474)  time: 0.8585  data: 0.0000  max mem: 20519
Epoch: [14]  [2000/3684]  eta: 0:24:22  loss: 41.4980 (61.6489)  time: 0.8865  data: 0.0000  max mem: 21228
Epoch: [14]  [2100/3684]  eta: 0:22:56  loss: 41.6760 (61.2433)  time: 0.8893  data: 0.0000  max mem: 21228
Epoch: [14]  [2200/3684]  eta: 0:21:28  loss: 38.4724 (61.2452)  time: 0.8732  data: 0.0000  max mem: 21228
Epoch: [14]  [2300/3684]  eta: 0:20:01  loss: 52.8065 (61.1429)  time: 0.8537  data: 0.0000  max mem: 21228
Epoch: [14]  [2400/3684]  eta: 0:18:34  loss: 63.0958 (60.8557)  time: 0.8705  data: 0.0000  max mem: 21228
Epoch: [14]  [2500/3684]  eta: 0:17:07  loss: 58.3607 (60.8649)  time: 0.8571  data: 0.0000  max mem: 21228
Epoch: [14]  [2600/3684]  eta: 0:15:40  loss: 58.6996 (60.7970)  time: 0.8587  data: 0.0000  max mem: 21228
Epoch: [14]  [2700/3684]  eta: 0:14:13  loss: 40.4824 (60.8709)  time: 0.8985  data: 0.0000  max mem: 21228
Epoch: [14]  [2800/3684]  eta: 0:12:47  loss: 51.4938 (60.7285)  time: 0.8729  data: 0.0000  max mem: 21228
Epoch: [14]  [2900/3684]  eta: 0:11:20  loss: 30.3842 (60.6635)  time: 0.8769  data: 0.0000  max mem: 21228
Epoch: [14]  [3000/3684]  eta: 0:09:53  loss: 44.6434 (60.6719)  time: 0.8661  data: 0.0000  max mem: 21228
Epoch: [14]  [3100/3684]  eta: 0:08:26  loss: 59.0091 (60.7537)  time: 0.8428  data: 0.0000  max mem: 21228
Epoch: [14]  [3200/3684]  eta: 0:06:59  loss: 62.1520 (60.9989)  time: 0.8860  data: 0.0000  max mem: 21228
Epoch: [14]  [3300/3684]  eta: 0:05:33  loss: 60.7448 (60.9362)  time: 0.8751  data: 0.0000  max mem: 21228
Epoch: [14]  [3400/3684]  eta: 0:04:06  loss: 29.9307 (60.8130)  time: 0.8612  data: 0.0000  max mem: 21228
Epoch: [14]  [3500/3684]  eta: 0:02:39  loss: 43.1674 (60.8857)  time: 0.8422  data: 0.0000  max mem: 21228
Epoch: [14]  [3600/3684]  eta: 0:01:12  loss: 25.1544 (60.6726)  time: 0.8850  data: 0.0000  max mem: 21228
Epoch: [14]  [3683/3684]  eta: 0:00:00  loss: 32.4959 (60.4503)  time: 0.8650  data: 0.0000  max mem: 21228
Epoch: [14] Total time: 0:53:13 (0.8669 s / it)
Averaged stats: loss: 32.4959 (60.4503)
Evaluating talk2event
Test:  [   0/3685]  eta: 0:25:52  loss: 15.9567 (15.9567)  time: 0.4213  data: 0.2973  max mem: 21228
Test:  [ 500/3685]  eta: 0:05:10  loss: 41.5611 (48.5033)  time: 0.0959  data: 0.0001  max mem: 21228
Test:  [1000/3685]  eta: 0:04:20  loss: 31.0094 (61.1340)  time: 0.0962  data: 0.0001  max mem: 21228
Test:  [1500/3685]  eta: 0:03:31  loss: 25.1979 (76.4508)  time: 0.0956  data: 0.0001  max mem: 21228
Test:  [2000/3685]  eta: 0:02:43  loss: 24.8168 (75.2496)  time: 0.0962  data: 0.0001  max mem: 21228
Test:  [2500/3685]  eta: 0:01:54  loss: 37.2337 (71.8572)  time: 0.0961  data: 0.0001  max mem: 21228
Test:  [3000/3685]  eta: 0:01:06  loss: 72.7596 (70.1523)  time: 0.0983  data: 0.0001  max mem: 21228
Test:  [3500/3685]  eta: 0:00:17  loss: 54.8203 (68.1297)  time: 0.0965  data: 0.0001  max mem: 21228
Test:  [3684/3685]  eta: 0:00:00  loss: 14.7435 (68.0065)  time: 0.0964  data: 0.0001  max mem: 21228
Test: Total time: 0:05:58 (0.0972 s / it)
Averaged stats: loss: 14.7435 (68.0065)
Epoch: [15]  [   0/3684]  eta: 1:09:54  loss: 83.1213 (83.1213)  time: 1.1386  data: 0.0000  max mem: 21228
Epoch: [15]  [ 100/3684]  eta: 0:51:40  loss: 40.6725 (56.2875)  time: 0.8651  data: 0.0000  max mem: 21228
Epoch: [15]  [ 200/3684]  eta: 0:50:09  loss: 42.9435 (59.1902)  time: 0.8669  data: 0.0000  max mem: 21228
Epoch: [15]  [ 300/3684]  eta: 0:48:45  loss: 32.5051 (58.9170)  time: 0.8692  data: 0.0000  max mem: 21228
Epoch: [15]  [ 400/3684]  eta: 0:47:15  loss: 21.1971 (59.0742)  time: 0.8772  data: 0.0000  max mem: 21228
Epoch: [15]  [ 500/3684]  eta: 0:45:43  loss: 56.3003 (58.2338)  time: 0.8685  data: 0.0000  max mem: 21228
Epoch: [15]  [ 600/3684]  eta: 0:44:26  loss: 30.6301 (57.6170)  time: 0.8928  data: 0.0000  max mem: 21228
Epoch: [15]  [ 700/3684]  eta: 0:43:00  loss: 51.9512 (58.2335)  time: 0.8292  data: 0.0000  max mem: 21228
Epoch: [15]  [ 800/3684]  eta: 0:41:36  loss: 39.9388 (58.7338)  time: 0.8635  data: 0.0000  max mem: 21228
Epoch: [15]  [ 900/3684]  eta: 0:40:27  loss: 22.6622 (58.3779)  time: 0.9606  data: 0.0000  max mem: 21228
Epoch: [15]  [1000/3684]  eta: 0:39:22  loss: 38.2023 (58.3345)  time: 0.9744  data: 0.0000  max mem: 21228
Epoch: [15]  [1100/3684]  eta: 0:38:13  loss: 48.7246 (58.1348)  time: 0.9681  data: 0.0000  max mem: 21228
Epoch: [15]  [1200/3684]  eta: 0:36:40  loss: 21.6641 (57.3522)  time: 0.8885  data: 0.0000  max mem: 21228
Epoch: [15]  [1300/3684]  eta: 0:35:10  loss: 38.6350 (56.7887)  time: 0.8895  data: 0.0000  max mem: 21228
Epoch: [15]  [1400/3684]  eta: 0:33:38  loss: 45.7421 (56.9196)  time: 0.8795  data: 0.0000  max mem: 21228
Epoch: [15]  [1500/3684]  eta: 0:32:07  loss: 23.8051 (56.5812)  time: 0.8684  data: 0.0000  max mem: 21228
Epoch: [15]  [1600/3684]  eta: 0:30:37  loss: 32.7186 (56.7333)  time: 0.8445  data: 0.0000  max mem: 21228
Epoch: [15]  [1700/3684]  eta: 0:29:08  loss: 38.3159 (56.5913)  time: 0.8829  data: 0.0000  max mem: 21228
Epoch: [15]  [1800/3684]  eta: 0:27:39  loss: 28.0548 (56.6078)  time: 0.8663  data: 0.0000  max mem: 21228
Epoch: [15]  [1900/3684]  eta: 0:26:11  loss: 56.8858 (56.6155)  time: 0.8910  data: 0.0000  max mem: 21228
Epoch: [15]  [2000/3684]  eta: 0:24:42  loss: 42.1821 (56.4173)  time: 0.8630  data: 0.0000  max mem: 21228
Epoch: [15]  [2100/3684]  eta: 0:23:12  loss: 41.0976 (56.3671)  time: 0.8576  data: 0.0000  max mem: 21228
Epoch: [15]  [2200/3684]  eta: 0:21:43  loss: 44.4242 (56.4131)  time: 0.8379  data: 0.0000  max mem: 21228
Epoch: [15]  [2300/3684]  eta: 0:20:14  loss: 49.8824 (56.4495)  time: 0.8700  data: 0.0000  max mem: 21228
Epoch: [15]  [2400/3684]  eta: 0:18:46  loss: 31.7456 (56.1845)  time: 0.8217  data: 0.0000  max mem: 21228
Epoch: [15]  [2500/3684]  eta: 0:17:17  loss: 68.7945 (56.3685)  time: 0.8580  data: 0.0000  max mem: 21228
Epoch: [15]  [2600/3684]  eta: 0:15:49  loss: 61.9005 (56.4580)  time: 0.8229  data: 0.0000  max mem: 21228
Epoch: [15]  [2700/3684]  eta: 0:14:21  loss: 36.6276 (56.8029)  time: 0.8584  data: 0.0000  max mem: 21228
Epoch: [15]  [2800/3684]  eta: 0:12:53  loss: 51.7011 (56.9487)  time: 0.8767  data: 0.0000  max mem: 21228
Epoch: [15]  [2900/3684]  eta: 0:11:25  loss: 49.9034 (56.7511)  time: 0.8387  data: 0.0000  max mem: 21228
Epoch: [15]  [3000/3684]  eta: 0:09:57  loss: 29.9181 (56.7947)  time: 0.8460  data: 0.0000  max mem: 21228
Epoch: [15]  [3100/3684]  eta: 0:08:30  loss: 38.2597 (56.7004)  time: 0.8212  data: 0.0000  max mem: 21228
Epoch: [15]  [3200/3684]  eta: 0:07:02  loss: 39.1324 (56.7163)  time: 0.8579  data: 0.0000  max mem: 21228
Epoch: [15]  [3300/3684]  eta: 0:05:35  loss: 27.9803 (56.5384)  time: 0.8562  data: 0.0000  max mem: 21228
Epoch: [15]  [3400/3684]  eta: 0:04:07  loss: 41.2291 (56.4307)  time: 0.8257  data: 0.0000  max mem: 21228
Epoch: [15]  [3500/3684]  eta: 0:02:40  loss: 56.4302 (56.6696)  time: 0.8724  data: 0.0000  max mem: 21228
Epoch: [15]  [3600/3684]  eta: 0:01:13  loss: 29.1162 (56.6472)  time: 0.8450  data: 0.0000  max mem: 21228
Epoch: [15]  [3683/3684]  eta: 0:00:00  loss: 28.1842 (56.7587)  time: 0.8587  data: 0.0000  max mem: 21228
Epoch: [15] Total time: 0:53:30 (0.8715 s / it)
Averaged stats: loss: 28.1842 (56.7587)
Evaluating talk2event
Test:  [   0/3685]  eta: 0:24:49  loss: 18.9786 (18.9786)  time: 0.4043  data: 0.2959  max mem: 21228
Test:  [ 500/3685]  eta: 0:05:10  loss: 57.5685 (49.1020)  time: 0.0964  data: 0.0001  max mem: 21228
Test:  [1000/3685]  eta: 0:04:22  loss: 46.2009 (61.6308)  time: 0.1022  data: 0.0001  max mem: 21228
Test:  [1500/3685]  eta: 0:03:33  loss: 47.0022 (75.9317)  time: 0.0964  data: 0.0001  max mem: 21228
Test:  [2000/3685]  eta: 0:02:44  loss: 33.5121 (74.1251)  time: 0.0962  data: 0.0001  max mem: 21228
Test:  [2500/3685]  eta: 0:01:55  loss: 50.9009 (70.3036)  time: 0.0962  data: 0.0001  max mem: 21228
Test:  [3000/3685]  eta: 0:01:06  loss: 50.7600 (68.0449)  time: 0.0968  data: 0.0001  max mem: 21228
Test:  [3500/3685]  eta: 0:00:17  loss: 61.0220 (66.0348)  time: 0.0974  data: 0.0001  max mem: 21228
Test:  [3684/3685]  eta: 0:00:00  loss: 18.1467 (65.8649)  time: 0.0964  data: 0.0001  max mem: 21228
Test: Total time: 0:05:58 (0.0973 s / it)
Averaged stats: loss: 18.1467 (65.8649)
Epoch: [16]  [   0/3684]  eta: 0:48:20  loss: 54.2432 (54.2432)  time: 0.7873  data: 0.0000  max mem: 21228
Epoch: [16]  [ 100/3684]  eta: 0:51:26  loss: 27.0336 (51.4879)  time: 0.8493  data: 0.0000  max mem: 21228
Epoch: [16]  [ 200/3684]  eta: 0:50:23  loss: 61.9113 (58.3296)  time: 0.8756  data: 0.0000  max mem: 21228
Epoch: [16]  [ 300/3684]  eta: 0:48:55  loss: 29.9992 (55.5355)  time: 0.8947  data: 0.0000  max mem: 21228
Epoch: [16]  [ 400/3684]  eta: 0:47:28  loss: 61.1931 (54.0602)  time: 0.8514  data: 0.0000  max mem: 21228
Epoch: [16]  [ 500/3684]  eta: 0:45:59  loss: 34.9276 (53.8006)  time: 0.8542  data: 0.0000  max mem: 21228
Epoch: [16]  [ 600/3684]  eta: 0:44:24  loss: 53.2381 (54.8593)  time: 0.8849  data: 0.0000  max mem: 21228
Epoch: [16]  [ 700/3684]  eta: 0:43:02  loss: 47.2523 (55.0487)  time: 0.8781  data: 0.0000  max mem: 21228
Epoch: [16]  [ 800/3684]  eta: 0:41:35  loss: 28.5001 (54.5219)  time: 0.8493  data: 0.0000  max mem: 21228
Epoch: [16]  [ 900/3684]  eta: 0:40:11  loss: 45.4185 (55.0323)  time: 0.8652  data: 0.0000  max mem: 21228
Epoch: [16]  [1000/3684]  eta: 0:38:43  loss: 62.9064 (55.2068)  time: 0.8787  data: 0.0000  max mem: 21228
Epoch: [16]  [1100/3684]  eta: 0:37:15  loss: 57.0004 (55.3291)  time: 0.8470  data: 0.0000  max mem: 21228
Epoch: [16]  [1200/3684]  eta: 0:35:51  loss: 43.3771 (55.5270)  time: 0.8798  data: 0.0000  max mem: 21228
Epoch: [16]  [1300/3684]  eta: 0:34:23  loss: 26.8440 (54.5341)  time: 0.8673  data: 0.0000  max mem: 21228
Epoch: [16]  [1400/3684]  eta: 0:32:57  loss: 43.1963 (54.4364)  time: 0.8738  data: 0.0000  max mem: 21228
Epoch: [16]  [1500/3684]  eta: 0:31:30  loss: 40.0816 (54.3348)  time: 0.8901  data: 0.0000  max mem: 21228
Epoch: [16]  [1600/3684]  eta: 0:30:02  loss: 47.0729 (54.4608)  time: 0.8407  data: 0.0000  max mem: 21228
Epoch: [16]  [1700/3684]  eta: 0:28:35  loss: 27.0744 (54.2371)  time: 0.8511  data: 0.0000  max mem: 21228
Epoch: [16]  [1800/3684]  eta: 0:27:10  loss: 43.9511 (54.3366)  time: 0.8941  data: 0.0000  max mem: 21228
Epoch: [16]  [1900/3684]  eta: 0:25:43  loss: 33.8185 (54.1264)  time: 0.8689  data: 0.0000  max mem: 21228
Epoch: [16]  [2000/3684]  eta: 0:24:16  loss: 43.9105 (54.2632)  time: 0.8735  data: 0.0000  max mem: 21228
Epoch: [16]  [2100/3684]  eta: 0:22:50  loss: 18.9803 (54.1703)  time: 0.9100  data: 0.0000  max mem: 21228
Epoch: [16]  [2200/3684]  eta: 0:21:23  loss: 48.1305 (54.3562)  time: 0.8823  data: 0.0000  max mem: 21228
Epoch: [16]  [2300/3684]  eta: 0:19:57  loss: 29.2086 (54.3611)  time: 0.8582  data: 0.0000  max mem: 21228
Epoch: [16]  [2400/3684]  eta: 0:18:30  loss: 40.5843 (54.3202)  time: 0.8500  data: 0.0000  max mem: 21228
Epoch: [16]  [2500/3684]  eta: 0:17:04  loss: 53.3367 (54.3685)  time: 0.8665  data: 0.0000  max mem: 21228
Epoch: [16]  [2600/3684]  eta: 0:15:38  loss: 37.1615 (54.3678)  time: 0.8717  data: 0.0000  max mem: 21228
Epoch: [16]  [2700/3684]  eta: 0:14:11  loss: 61.6339 (54.5363)  time: 0.8407  data: 0.0000  max mem: 21228
Epoch: [16]  [2800/3684]  eta: 0:12:45  loss: 28.0990 (54.5692)  time: 0.8683  data: 0.0000  max mem: 21228
Epoch: [16]  [2900/3684]  eta: 0:11:18  loss: 23.9714 (54.4124)  time: 0.8612  data: 0.0000  max mem: 21228
Epoch: [16]  [3000/3684]  eta: 0:09:52  loss: 32.9318 (54.4787)  time: 0.8277  data: 0.0000  max mem: 21228
Epoch: [16]  [3100/3684]  eta: 0:08:25  loss: 37.6963 (54.4899)  time: 0.8416  data: 0.0000  max mem: 21228
Epoch: [16]  [3200/3684]  eta: 0:06:58  loss: 24.2369 (54.6328)  time: 0.8699  data: 0.0000  max mem: 21228
Epoch: [16]  [3300/3684]  eta: 0:05:32  loss: 58.7129 (54.6082)  time: 0.8796  data: 0.0000  max mem: 21228
Epoch: [16]  [3400/3684]  eta: 0:04:05  loss: 33.0244 (54.4037)  time: 0.8563  data: 0.0000  max mem: 21228
Epoch: [16]  [3500/3684]  eta: 0:02:39  loss: 52.2602 (54.3332)  time: 0.8397  data: 0.0000  max mem: 21228
Epoch: [16]  [3600/3684]  eta: 0:01:12  loss: 52.0776 (54.3101)  time: 0.8576  data: 0.0000  max mem: 21228
Epoch: [16]  [3683/3684]  eta: 0:00:00  loss: 31.8686 (54.2514)  time: 0.8798  data: 0.0000  max mem: 21228
Epoch: [16] Total time: 0:53:07 (0.8651 s / it)
Averaged stats: loss: 31.8686 (54.2514)
Evaluating talk2event
Test:  [   0/3685]  eta: 0:29:37  loss: 27.2820 (27.2820)  time: 0.4824  data: 0.3566  max mem: 21228
Test:  [ 500/3685]  eta: 0:05:10  loss: 56.5640 (55.3670)  time: 0.0969  data: 0.0001  max mem: 21228
Test:  [1000/3685]  eta: 0:04:20  loss: 48.5655 (65.3723)  time: 0.0964  data: 0.0001  max mem: 21228
Test:  [1500/3685]  eta: 0:03:31  loss: 52.5094 (79.1926)  time: 0.0961  data: 0.0001  max mem: 21228
Test:  [2000/3685]  eta: 0:02:42  loss: 49.9763 (77.0029)  time: 0.0961  data: 0.0001  max mem: 21228
Test:  [2500/3685]  eta: 0:01:54  loss: 59.6270 (73.8121)  time: 0.0962  data: 0.0001  max mem: 21228
Test:  [3000/3685]  eta: 0:01:06  loss: 46.7508 (71.0891)  time: 0.0974  data: 0.0001  max mem: 21228
Test:  [3500/3685]  eta: 0:00:17  loss: 58.5923 (69.3057)  time: 0.0966  data: 0.0001  max mem: 21228
Test:  [3684/3685]  eta: 0:00:00  loss: 26.5161 (69.1367)  time: 0.0973  data: 0.0001  max mem: 21228
Test: Total time: 0:05:56 (0.0969 s / it)
Averaged stats: loss: 26.5161 (69.1367)
Epoch: [17]  [   0/3684]  eta: 0:48:53  loss: 17.5439 (17.5439)  time: 0.7963  data: 0.0000  max mem: 21228
Epoch: [17]  [ 100/3684]  eta: 0:51:39  loss: 44.9766 (50.1770)  time: 0.8498  data: 0.0000  max mem: 21228
Epoch: [17]  [ 200/3684]  eta: 0:50:06  loss: 37.7490 (54.3885)  time: 0.8719  data: 0.0000  max mem: 21228
Epoch: [17]  [ 300/3684]  eta: 0:48:39  loss: 18.6558 (51.2809)  time: 0.8682  data: 0.0000  max mem: 21228
Epoch: [17]  [ 400/3684]  eta: 0:47:20  loss: 30.8968 (51.0354)  time: 0.8611  data: 0.0000  max mem: 21228
Epoch: [17]  [ 500/3684]  eta: 0:45:52  loss: 32.4930 (51.9884)  time: 0.8947  data: 0.0000  max mem: 21228
Epoch: [17]  [ 600/3684]  eta: 0:44:30  loss: 32.8763 (52.2075)  time: 0.8817  data: 0.0000  max mem: 21228
Epoch: [17]  [ 700/3684]  eta: 0:42:56  loss: 45.9097 (51.8877)  time: 0.8549  data: 0.0000  max mem: 21228
Epoch: [17]  [ 800/3684]  eta: 0:41:26  loss: 35.9347 (51.6284)  time: 0.8478  data: 0.0000  max mem: 21228
Epoch: [17]  [ 900/3684]  eta: 0:39:58  loss: 34.3578 (51.3792)  time: 0.8599  data: 0.0000  max mem: 21228
Epoch: [17]  [1000/3684]  eta: 0:38:31  loss: 36.2729 (51.0538)  time: 0.8393  data: 0.0000  max mem: 21228
Epoch: [17]  [1100/3684]  eta: 0:37:04  loss: 58.9746 (51.9072)  time: 0.8490  data: 0.0000  max mem: 21228
Epoch: [17]  [1200/3684]  eta: 0:35:36  loss: 26.9616 (51.3809)  time: 0.8175  data: 0.0000  max mem: 21228
Epoch: [17]  [1300/3684]  eta: 0:34:13  loss: 25.3790 (52.1401)  time: 0.8861  data: 0.0000  max mem: 21228
Epoch: [17]  [1400/3684]  eta: 0:32:46  loss: 52.9313 (52.1698)  time: 0.8590  data: 0.0000  max mem: 21228
Epoch: [17]  [1500/3684]  eta: 0:31:23  loss: 32.4148 (52.0243)  time: 0.9069  data: 0.0000  max mem: 21228
Epoch: [17]  [1600/3684]  eta: 0:29:59  loss: 33.0739 (51.9293)  time: 0.8757  data: 0.0000  max mem: 21228
Epoch: [17]  [1700/3684]  eta: 0:28:32  loss: 39.7484 (52.2946)  time: 0.8673  data: 0.0000  max mem: 21228
Epoch: [17]  [1800/3684]  eta: 0:27:05  loss: 22.6951 (52.2873)  time: 0.8514  data: 0.0000  max mem: 21228
Epoch: [17]  [1900/3684]  eta: 0:25:40  loss: 30.6967 (52.7092)  time: 0.8978  data: 0.0000  max mem: 21228
Epoch: [17]  [2000/3684]  eta: 0:24:14  loss: 24.8175 (52.5713)  time: 0.8494  data: 0.0000  max mem: 21228
Epoch: [17]  [2100/3684]  eta: 0:22:48  loss: 33.6679 (52.3821)  time: 0.8482  data: 0.0000  max mem: 21228
Epoch: [17]  [2200/3684]  eta: 0:21:23  loss: 23.3536 (52.4096)  time: 0.9003  data: 0.0000  max mem: 21228
Epoch: [17]  [2300/3684]  eta: 0:19:56  loss: 36.3917 (52.5840)  time: 0.8046  data: 0.0000  max mem: 21228
Epoch: [17]  [2400/3684]  eta: 0:18:29  loss: 43.8833 (52.4712)  time: 0.8744  data: 0.0000  max mem: 21228
Epoch: [17]  [2500/3684]  eta: 0:17:04  loss: 27.1767 (52.2964)  time: 0.8591  data: 0.0000  max mem: 21228
Epoch: [17]  [2600/3684]  eta: 0:15:37  loss: 45.1116 (52.4047)  time: 0.8782  data: 0.0000  max mem: 21228
Epoch: [17]  [2700/3684]  eta: 0:14:11  loss: 55.5529 (52.6137)  time: 0.8554  data: 0.0000  max mem: 21228
Epoch: [17]  [2800/3684]  eta: 0:12:45  loss: 65.5964 (52.7147)  time: 0.8638  data: 0.0000  max mem: 21228
Epoch: [17]  [2900/3684]  eta: 0:11:18  loss: 27.5124 (52.7008)  time: 0.8591  data: 0.0000  max mem: 21228
Epoch: [17]  [3000/3684]  eta: 0:09:51  loss: 22.9576 (52.8988)  time: 0.8651  data: 0.0000  max mem: 21228
Epoch: [17]  [3100/3684]  eta: 0:08:24  loss: 46.2554 (52.7491)  time: 0.8207  data: 0.0000  max mem: 21228
Epoch: [17]  [3200/3684]  eta: 0:06:58  loss: 44.7652 (52.7466)  time: 0.8576  data: 0.0000  max mem: 21228
Epoch: [17]  [3300/3684]  eta: 0:05:31  loss: 39.6173 (52.8008)  time: 0.8525  data: 0.0000  max mem: 21228
Epoch: [17]  [3400/3684]  eta: 0:04:05  loss: 32.8444 (52.8672)  time: 0.8725  data: 0.0000  max mem: 21228
Epoch: [17]  [3500/3684]  eta: 0:02:39  loss: 32.3583 (52.9392)  time: 0.9371  data: 0.0000  max mem: 21228
Epoch: [17]  [3600/3684]  eta: 0:01:12  loss: 56.6868 (53.0976)  time: 0.8790  data: 0.0000  max mem: 21228
Epoch: [17]  [3683/3684]  eta: 0:00:00  loss: 41.2284 (53.1287)  time: 0.8956  data: 0.0000  max mem: 21228
Epoch: [17] Total time: 0:53:13 (0.8670 s / it)
Averaged stats: loss: 41.2284 (53.1287)
Evaluating talk2event
Test:  [   0/3685]  eta: 0:30:25  loss: 33.0170 (33.0170)  time: 0.4954  data: 0.3675  max mem: 21228
Test:  [ 500/3685]  eta: 0:05:10  loss: 53.0677 (61.4356)  time: 0.0964  data: 0.0001  max mem: 21228
Test:  [1000/3685]  eta: 0:04:23  loss: 56.6877 (70.5782)  time: 0.1022  data: 0.0001  max mem: 21228
Test:  [1500/3685]  eta: 0:03:35  loss: 60.4639 (84.0452)  time: 0.0964  data: 0.0001  max mem: 21228
Test:  [2000/3685]  eta: 0:02:45  loss: 52.5865 (81.9017)  time: 0.0964  data: 0.0001  max mem: 21228
Test:  [2500/3685]  eta: 0:01:55  loss: 68.6213 (78.5993)  time: 0.0960  data: 0.0001  max mem: 21228
Test:  [3000/3685]  eta: 0:01:06  loss: 43.4578 (75.6232)  time: 0.0967  data: 0.0001  max mem: 21228
Test:  [3500/3685]  eta: 0:00:18  loss: 67.0684 (73.8671)  time: 0.0962  data: 0.0001  max mem: 21228
Test:  [3684/3685]  eta: 0:00:00  loss: 46.7758 (73.7428)  time: 0.0965  data: 0.0001  max mem: 21228
Test: Total time: 0:05:59 (0.0975 s / it)
Averaged stats: loss: 46.7758 (73.7428)
Epoch: [18]  [   0/3684]  eta: 0:54:49  loss: 79.4040 (79.4040)  time: 0.8928  data: 0.0000  max mem: 21228
Epoch: [18]  [ 100/3684]  eta: 0:52:22  loss: 29.5501 (51.9597)  time: 0.8232  data: 0.0000  max mem: 21228
Epoch: [18]  [ 200/3684]  eta: 0:50:30  loss: 31.8133 (52.5622)  time: 0.8389  data: 0.0000  max mem: 21228
Epoch: [18]  [ 300/3684]  eta: 0:49:00  loss: 28.5666 (50.1700)  time: 0.8480  data: 0.0000  max mem: 21228
Epoch: [18]  [ 400/3684]  eta: 0:47:24  loss: 27.7949 (49.4526)  time: 0.8327  data: 0.0000  max mem: 21228
Epoch: [18]  [ 500/3684]  eta: 0:45:53  loss: 27.3247 (49.2594)  time: 0.8445  data: 0.0000  max mem: 21228
Epoch: [18]  [ 600/3684]  eta: 0:44:28  loss: 38.7324 (52.4205)  time: 0.8813  data: 0.0000  max mem: 21228
Epoch: [18]  [ 700/3684]  eta: 0:43:01  loss: 50.4952 (51.6375)  time: 0.8580  data: 0.0000  max mem: 21228
Epoch: [18]  [ 800/3684]  eta: 0:41:32  loss: 45.9313 (51.8970)  time: 0.8456  data: 0.0000  max mem: 21228
Epoch: [18]  [ 900/3684]  eta: 0:40:07  loss: 59.4776 (51.8168)  time: 0.8668  data: 0.0000  max mem: 21228
Epoch: [18]  [1000/3684]  eta: 0:38:39  loss: 25.6594 (51.6351)  time: 0.8589  data: 0.0000  max mem: 21228
Epoch: [18]  [1100/3684]  eta: 0:37:15  loss: 18.8784 (51.0962)  time: 0.8549  data: 0.0000  max mem: 21228
Epoch: [18]  [1200/3684]  eta: 0:35:49  loss: 26.7812 (51.2319)  time: 0.8632  data: 0.0000  max mem: 21228
Epoch: [18]  [1300/3684]  eta: 0:34:24  loss: 75.6870 (51.3133)  time: 0.8846  data: 0.0000  max mem: 21228
Epoch: [18]  [1400/3684]  eta: 0:32:57  loss: 22.0669 (51.4490)  time: 0.8888  data: 0.0000  max mem: 21228
Epoch: [18]  [1500/3684]  eta: 0:31:30  loss: 28.3948 (51.7943)  time: 0.8665  data: 0.0000  max mem: 21228
Epoch: [18]  [1600/3684]  eta: 0:30:04  loss: 45.6935 (51.8789)  time: 0.8574  data: 0.0000  max mem: 21228
Epoch: [18]  [1700/3684]  eta: 0:28:37  loss: 48.2845 (51.7555)  time: 0.8657  data: 0.0000  max mem: 21228
Epoch: [18]  [1800/3684]  eta: 0:27:10  loss: 33.4643 (51.8320)  time: 0.8468  data: 0.0000  max mem: 21228
Epoch: [18]  [1900/3684]  eta: 0:25:42  loss: 31.1630 (52.0194)  time: 0.8364  data: 0.0000  max mem: 21228
Epoch: [18]  [2000/3684]  eta: 0:24:15  loss: 24.0121 (52.1925)  time: 0.8449  data: 0.0000  max mem: 21228
Epoch: [18]  [2100/3684]  eta: 0:22:49  loss: 39.9225 (52.1481)  time: 0.8795  data: 0.0000  max mem: 21228
Epoch: [18]  [2200/3684]  eta: 0:21:22  loss: 25.5771 (52.0130)  time: 0.8693  data: 0.0000  max mem: 21228
Epoch: [18]  [2300/3684]  eta: 0:19:55  loss: 27.5633 (51.8736)  time: 0.8562  data: 0.0000  max mem: 21228
Epoch: [18]  [2400/3684]  eta: 0:18:32  loss: 46.9070 (52.0461)  time: 0.9438  data: 0.0000  max mem: 21228
Epoch: [18]  [2500/3684]  eta: 0:17:08  loss: 40.6472 (51.9808)  time: 0.8812  data: 0.0000  max mem: 21228
Epoch: [18]  [2600/3684]  eta: 0:15:41  loss: 29.1051 (52.1882)  time: 0.8501  data: 0.0000  max mem: 21228
Epoch: [18]  [2700/3684]  eta: 0:14:13  loss: 43.7144 (52.1187)  time: 0.8626  data: 0.0000  max mem: 21228
Epoch: [18]  [2800/3684]  eta: 0:12:46  loss: 21.7583 (51.9680)  time: 0.8538  data: 0.0000  max mem: 21228
Epoch: [18]  [2900/3684]  eta: 0:11:19  loss: 57.4356 (51.9333)  time: 0.8284  data: 0.0000  max mem: 21228
Epoch: [18]  [3000/3684]  eta: 0:09:52  loss: 23.9958 (51.6302)  time: 0.8695  data: 0.0000  max mem: 21228
Epoch: [18]  [3100/3684]  eta: 0:08:25  loss: 40.3252 (51.7875)  time: 0.8251  data: 0.0000  max mem: 21228
Epoch: [18]  [3200/3684]  eta: 0:06:59  loss: 53.8519 (51.8324)  time: 0.8615  data: 0.0000  max mem: 21228
Epoch: [18]  [3300/3684]  eta: 0:05:32  loss: 27.7898 (51.7130)  time: 0.8840  data: 0.0000  max mem: 21228
Epoch: [18]  [3400/3684]  eta: 0:04:06  loss: 70.3062 (51.9469)  time: 0.9015  data: 0.0000  max mem: 21228
Epoch: [18]  [3500/3684]  eta: 0:02:39  loss: 50.5517 (52.0106)  time: 0.8392  data: 0.0000  max mem: 21228
Epoch: [18]  [3600/3684]  eta: 0:01:12  loss: 34.2923 (51.8936)  time: 0.8955  data: 0.0000  max mem: 21228
Epoch: [18]  [3683/3684]  eta: 0:00:00  loss: 37.5436 (51.7824)  time: 0.9013  data: 0.0000  max mem: 21228
Epoch: [18] Total time: 0:53:09 (0.8659 s / it)
Averaged stats: loss: 37.5436 (51.7824)
Evaluating talk2event
Test:  [   0/3685]  eta: 0:31:33  loss: 33.7844 (33.7844)  time: 0.5138  data: 0.3927  max mem: 21228
Test:  [ 500/3685]  eta: 0:05:10  loss: 52.7430 (63.4953)  time: 0.0962  data: 0.0001  max mem: 21228
Test:  [1000/3685]  eta: 0:04:20  loss: 53.5377 (72.5175)  time: 0.0965  data: 0.0001  max mem: 21228
Test:  [1500/3685]  eta: 0:03:32  loss: 63.9566 (85.7700)  time: 0.0966  data: 0.0001  max mem: 21228
Test:  [2000/3685]  eta: 0:02:43  loss: 53.7938 (84.0931)  time: 0.0961  data: 0.0001  max mem: 21228
Test:  [2500/3685]  eta: 0:01:54  loss: 65.9795 (80.3902)  time: 0.0967  data: 0.0001  max mem: 21228
Test:  [3000/3685]  eta: 0:01:06  loss: 51.3329 (77.4826)  time: 0.0977  data: 0.0001  max mem: 21228
Test:  [3500/3685]  eta: 0:00:17  loss: 60.0707 (75.7578)  time: 0.0974  data: 0.0001  max mem: 21228
Test:  [3684/3685]  eta: 0:00:00  loss: 43.3087 (75.6182)  time: 0.0970  data: 0.0001  max mem: 21228
Test: Total time: 0:05:57 (0.0971 s / it)
Averaged stats: loss: 43.3087 (75.6182)
Epoch: [19]  [   0/3684]  eta: 0:49:08  loss: 31.3609 (31.3609)  time: 0.8005  data: 0.0000  max mem: 21228
Epoch: [19]  [ 100/3684]  eta: 0:51:16  loss: 35.6785 (55.5610)  time: 0.8665  data: 0.0000  max mem: 21228
Epoch: [19]  [ 200/3684]  eta: 0:52:39  loss: 19.0684 (51.3736)  time: 0.9902  data: 0.0000  max mem: 21228
Epoch: [19]  [ 300/3684]  eta: 0:51:52  loss: 28.3829 (53.8304)  time: 0.9390  data: 0.0000  max mem: 21228
Epoch: [19]  [ 400/3684]  eta: 0:49:51  loss: 22.5861 (54.7783)  time: 0.8679  data: 0.0000  max mem: 21228
Epoch: [19]  [ 500/3684]  eta: 0:47:56  loss: 53.7743 (56.1947)  time: 0.8748  data: 0.0000  max mem: 21228
Epoch: [19]  [ 600/3684]  eta: 0:46:03  loss: 19.9808 (53.7802)  time: 0.8404  data: 0.0000  max mem: 21228
Epoch: [19]  [ 700/3684]  eta: 0:44:14  loss: 49.7152 (54.2239)  time: 0.8960  data: 0.0000  max mem: 21228
Epoch: [19]  [ 800/3684]  eta: 0:42:35  loss: 41.7752 (53.9118)  time: 0.8465  data: 0.0000  max mem: 21228
Epoch: [19]  [ 900/3684]  eta: 0:41:16  loss: 27.6151 (53.7064)  time: 0.9470  data: 0.0000  max mem: 21228
Epoch: [19]  [1000/3684]  eta: 0:40:03  loss: 40.6567 (53.4132)  time: 0.9499  data: 0.0000  max mem: 21228
Epoch: [19]  [1100/3684]  eta: 0:38:46  loss: 33.9783 (53.4538)  time: 0.9269  data: 0.0000  max mem: 21228
Epoch: [19]  [1200/3684]  eta: 0:37:17  loss: 47.2805 (52.7568)  time: 0.8779  data: 0.0000  max mem: 21228
Epoch: [19]  [1300/3684]  eta: 0:35:45  loss: 29.6546 (51.9970)  time: 0.9313  data: 0.0000  max mem: 21228
Epoch: [19]  [1400/3684]  eta: 0:34:22  loss: 53.8242 (52.3380)  time: 0.9444  data: 0.0000  max mem: 21228
Epoch: [19]  [1500/3684]  eta: 0:32:51  loss: 31.5338 (52.2339)  time: 0.8567  data: 0.0000  max mem: 21228
Epoch: [19]  [1600/3684]  eta: 0:31:18  loss: 24.7966 (51.8780)  time: 0.8872  data: 0.0000  max mem: 21228
Epoch: [19]  [1700/3684]  eta: 0:29:44  loss: 27.9042 (51.5892)  time: 0.8700  data: 0.0000  max mem: 21228
Epoch: [19]  [1800/3684]  eta: 0:28:09  loss: 39.6711 (51.9161)  time: 0.8424  data: 0.0000  max mem: 21228
Epoch: [19]  [1900/3684]  eta: 0:26:38  loss: 33.7123 (51.6937)  time: 0.8835  data: 0.0000  max mem: 21228
Epoch: [19]  [2000/3684]  eta: 0:25:06  loss: 25.2649 (51.4884)  time: 0.8599  data: 0.0000  max mem: 21228
Epoch: [19]  [2100/3684]  eta: 0:23:34  loss: 36.6896 (51.1509)  time: 0.8662  data: 0.0000  max mem: 21228
Epoch: [19]  [2200/3684]  eta: 0:22:03  loss: 31.4701 (51.0643)  time: 0.8507  data: 0.0000  max mem: 21228
Epoch: [19]  [2300/3684]  eta: 0:20:32  loss: 29.4137 (51.0277)  time: 0.8756  data: 0.0000  max mem: 21228
Epoch: [19]  [2400/3684]  eta: 0:19:01  loss: 27.2482 (51.1950)  time: 0.8448  data: 0.0000  max mem: 21228
Epoch: [19]  [2500/3684]  eta: 0:17:31  loss: 21.8949 (51.1313)  time: 0.9057  data: 0.0000  max mem: 21228
Epoch: [19]  [2600/3684]  eta: 0:16:02  loss: 26.7863 (50.9340)  time: 0.9531  data: 0.0000  max mem: 21228
Epoch: [19]  [2700/3684]  eta: 0:14:35  loss: 32.9015 (50.9845)  time: 0.9232  data: 0.0000  max mem: 21228
Epoch: [19]  [2800/3684]  eta: 0:13:07  loss: 19.0647 (51.0362)  time: 0.8536  data: 0.0000  max mem: 21228
Epoch: [19]  [2900/3684]  eta: 0:11:37  loss: 28.3560 (51.0600)  time: 0.8709  data: 0.0000  max mem: 21228
Epoch: [19]  [3000/3684]  eta: 0:10:07  loss: 34.1297 (51.1321)  time: 0.8579  data: 0.0000  max mem: 21228
Epoch: [19]  [3100/3684]  eta: 0:08:38  loss: 36.2929 (51.1984)  time: 0.8226  data: 0.0000  max mem: 21228
Epoch: [19]  [3200/3684]  eta: 0:07:09  loss: 31.9974 (51.2802)  time: 0.8635  data: 0.0000  max mem: 21228
Epoch: [19]  [3300/3684]  eta: 0:05:39  loss: 38.5409 (51.0926)  time: 0.8149  data: 0.0000  max mem: 21228
Epoch: [19]  [3400/3684]  eta: 0:04:11  loss: 30.7585 (50.9049)  time: 0.8400  data: 0.0000  max mem: 21228
Epoch: [19]  [3500/3684]  eta: 0:02:42  loss: 28.4588 (50.7488)  time: 0.8815  data: 0.0000  max mem: 21228
Epoch: [19]  [3600/3684]  eta: 0:01:14  loss: 39.5390 (50.8390)  time: 0.8572  data: 0.0000  max mem: 21228
Epoch: [19]  [3683/3684]  eta: 0:00:00  loss: 29.4488 (50.6742)  time: 0.8371  data: 0.0000  max mem: 21228
Epoch: [19] Total time: 0:54:11 (0.8826 s / it)
Averaged stats: loss: 29.4488 (50.6742)
Evaluating talk2event
Test:  [   0/3685]  eta: 0:32:27  loss: 47.1444 (47.1444)  time: 0.5286  data: 0.4128  max mem: 21228
Test:  [ 500/3685]  eta: 0:05:10  loss: 61.9431 (64.9273)  time: 0.0961  data: 0.0001  max mem: 21228
Test:  [1000/3685]  eta: 0:04:20  loss: 60.3817 (73.5538)  time: 0.0964  data: 0.0001  max mem: 21228
Test:  [1500/3685]  eta: 0:03:31  loss: 68.1002 (86.5656)  time: 0.0960  data: 0.0001  max mem: 21228
Test:  [2000/3685]  eta: 0:02:43  loss: 56.7422 (85.1674)  time: 0.0962  data: 0.0001  max mem: 21228
Test:  [2500/3685]  eta: 0:01:54  loss: 71.0876 (81.5621)  time: 0.0971  data: 0.0001  max mem: 21228
Test:  [3000/3685]  eta: 0:01:06  loss: 56.8012 (78.6838)  time: 0.0965  data: 0.0001  max mem: 21228
Test:  [3500/3685]  eta: 0:00:17  loss: 59.7216 (77.0255)  time: 0.1025  data: 0.0001  max mem: 21228
Test:  [3684/3685]  eta: 0:00:00  loss: 50.9504 (76.9393)  time: 0.1025  data: 0.0001  max mem: 21228
Test: Total time: 0:05:57 (0.0971 s / it)
Averaged stats: loss: 50.9504 (76.9393)
Training time 6:57:19
